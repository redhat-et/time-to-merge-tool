# We run this workflow on the base ocp-ci-analysis container image which contains dependencies neccesary to run these notebooks 
name: Run in container

# Controls when the workflow will run
on:

  repository_dispatch:
  # Allows submitting to this workflow using client payload
  workflow_dispatch:
  # Allows you to run this workflow manually from the Actions tab
  # A workflow run is made up of one or more jobs that can run sequentially or in parallel

jobs:
  pipeline:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    container: 
      image: quay.io/aicoe/ocp-ci-analysis
    if: ${{ github.event.client_payload.AWS_ACCESS_KEY_ID.passed }} == true
    env:
      
      AWS_ACCESS_KEY_ID: ${{ github.event.client_payload.AWS_ACCESS_KEY_ID  || secrets.AWS_ACCESS_KEY_ID}}
    
      GITHUB_REPO: ${{ github.event.client_payload.REPO || secrets.REPO }}
      GITHUB_ORG: ${{ github.event.client_payload.ORG || secrets.ORG }}

      S3_ENDPOINT_URL: ${{ github.event.client_payload.S3_ENDPOINT_URL || secrets.S3_ENDPOINT_URL }}
      S3_BUCKET: ${{ github.event.client_payload.S3_BUCKET || secrets.S3_BUCKET }}
      AWS_SECRET_ACCESS_KEY: ${{ github.event.client_payload.AWS_SECRET_ACCESS_KEY || secrets.AWS_SECRET_ACCESS_KEY }}

      CEPH_BUCKET: ${{ github.event.client_payload.S3_BUCKET || secrets.S3_BUCKET }}
      CEPH_BUCKET_PREFIX: ${{ github.event.client_payload.PREFIX|| secrets.CEPH_BUCKET_PREFIX }}
      CEPH_KEY_ID: ${{ github.event.client_payload.AWS_ACCESS_KEY_ID  || secrets.AWS_ACCESS_KEY_ID }}
      CEPH_SECRET_KEY: ${{ github.event.client_payload.AWS_SECRET_ACCESS_KEY || secrets.AWS_SECRET_ACCESS_KEY }}

      GITHUB_ACCESS_TOKEN: ${{ secrets.GITHUB_TOKEN || secrets.ACCESS_TOKEN}}
      
      REMOTE: 1

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - name: Checkout repo
        uses: actions/checkout@v2
        
#       - name: Data Collection notebook
#         run: jupyter nbconvert --to notebook --execute 01_data_collection.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 01_notebook_executed
#       - name: commit updated notebook
#         uses: EndBug/add-and-commit@v7
#         with:
#           author_name: update notebook with pipeline
#           message: "Update Notebook"
#           add: "01_notebook_executed.ipynb"

      - name: Run data collection
        run: python data_collection.py
      - name: Feature Engineering notebook
        run: jupyter nbconvert --to notebook --execute 02_feature_engineering.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 02_notebook_executed
      - name: commit updated notebook 2
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Update Notebook 2"
          add: "02_notebook_executed.ipynb"
      - name: Model Training notebook
        run: jupyter nbconvert --to notebook --execute 03_model_training.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 03_notebook_executed
      - name: commit updated notebook 3
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Update Notebook 3"
          add: "03_notebook_executed.ipynb"
      - name: Model Inference notebook
        run: jupyter nbconvert --to notebook --execute 04_model_inference.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 04_notebook_executed
      - name: commit updated notebook 4
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Update Notebook 4"
          add: "04_notebook_executed.ipynb" 
